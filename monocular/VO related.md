### 7.1.1 特征点
相比于朴素的角点，这些人工设计的特征点能够拥有如下性质：
1. 可重复性（Repeatability）：相同的特征可以在不同的图像中找到。
2. 可区别性（Distinctiveness）：不同的特征有不同的表达。
3. 高效率（Efficiency）：同一图像中，特征点的数量应远小于像素的数量。
4. 本地性（Locality）：特征仅与一小片图像区域相关。

描述子是按照“外观相似的特征应该有相似的描述子”的原则设计的。

### 7.1.2 ORB特征
**FAST关键点**

**BRIEF描述子**


## 7.3 2D-2D：对极几何
### 7.3.1 对极约束
![](/monocular/img/duiou.png)
同时，如果不知道P的位置，那么当我们在第二幅图像上看时，连线e<sub>2</sub>p<sub>2</sub>（也就是第二幅图像中的极线）就是P可能出现的投影位置，也就是射线O<sub>1</sub>p<sub>1</sub>在第二个相机中的投影。

基础矩阵(Fundamental Matrix)F 和本质矩阵(Essential Matrix)E
<br> 相机内参在SLAM中通常是已知的，在SfM研究中则有可能是未知且有待估计的

$$E=t^{\wedge }R,   F=K^{-T}EK^{-1}=K^{-T}t^{\wedge }RK^{-1}$$
$$P=\begin{pmatrix}
 X
\\Y
 \\Z
\end{pmatrix} 

,p=\begin{pmatrix}
 u
\\v
 \\1
\end{pmatrix}

,x=\begin{pmatrix}
 X/Z 
\\Y/Z 
 \\1
\end{pmatrix}$$
$$ x_{2}^{T}Ex_{1} = p_{2}^{T}Fp_{1} = 0 $$
### 7.3.2 本质矩阵
E实际上有5个自由度

八点法  
Improve accuracy of 8-point algorithm [Har97]

奇异值分解本质矩阵，得到t与R
<br> 引入谱定理
<br> t的方向是奇异值0对应的奇异向量

### 7.3.3 单应矩阵
单应矩阵通常描述处于**共同平面**上的一些点在两张图像之间的变换关系。
<br> 这些情况在无人机携带的俯视相机或扫地机携带的顶视相机中比较常见。

$$ H=K(R-\frac{tn^{T}}{d})K^{-1}  $$

$$ p_{2} \simeq Hp_{1} $$

于是自由度为8的单应矩阵（尺度等价性）可以通过4对匹配特征点算出（在非退化的情况下，即这些特征点不能有三点共线的情况）
<br> 直接线性变换法

分解的方法包括数值法和解析法

当特征点共面或者相机发生纯旋转时，基础矩阵的自由度下降，这就出现了所谓的退化（degenerate）。

分解得到的R,t一共有4种可能性，不过，OpenCV会替我们检测角点的深度是否为正，从而选出正确的解

### 讨论
在单目视觉中，我们对两张图像的t归一化相当于固定了尺度。虽然我们不知道它的实际长度是多少，但我们以这时的t为单位1，计算相机运动和特征点的3D位置。这被称为单目SLAM的初始化。在初始化之后，就可以用3D-2D计算相机运动了。初始化之后的轨迹和地图的单位，就是初始化时固定的尺度。因此，单目SLAM有一步不可避免的初始化。初始化的两张图像必须有一定程度的平移，而后的轨迹和地图都将以此步的平移为单位。  
除了对t进行归一化，另一种方法是令初始化时所有的特征点平均深度为1，也可以固定一个尺度。相比于令t长度为1的做法，把特征点深度归一化可以控制场景的规模大小，使计算在数值上更稳定。

对于八点法，如果给定的匹配点多于8，则方程构成一个超定方程，即不一定存在e使得上式成立。因此，可以通过最小化一个二次型来求：
$$ \min_{e}\left \| Ae \right \|_{2}^{2} = \min_{e}e^{T}A^{T}Ae   $$
不过，当可能存在误匹配的情况时，我们会更倾向于使用**随机采样一致性(RANSAC)** 来求。

## 7.5 三角测量
通过三角测量（Triangulation）（或三角化）的方法估计地图点的深度  
三角测量是指，通过不同位置对同一个路标点进行观察，从观察到的位置推断路标点的距离。

![](/monocular/img/7.5.jpeg)

当然，由于噪声的存在，我们估计得的R,t不一定精确使上式为零，所以更常见的做法是求最小二乘解而不是直接的解。
<br> [[学习SLAM ]单目vo中的深度确定方法--三角测量](https://blog.csdn.net/KYJL888/article/details/107222533)

**三角测量是由平移得到的，有平移才会有对极几何中的三角形，才谈得上三角测量。**  
仅旋转光心位置没有发生改变，还是同一条极线。  
总而言之， 增大平移，可能导致匹配失效；而平移太小，则三角化精度不够。我们把这个问题称为“视差”（parallax）。

## 7.7 3D-2D: PnP
如果两张图像中的一张特征点的3D位置已知，那么最少只需3个点对（以及至少一个额外点验证结果）就可以估计相机运动。  
特征点的3D位置可以由三角化或者RGB-D相机的深度图确定。而在单目视觉里程计中，必须先进行初始化，才能使用PnP。

### 7.7.1 直接线性变换（DLT）
$$s\begin{pmatrix}
 u_{1} 
\\v_{1}
 \\1
\end{pmatrix}
= T\begin{pmatrix}
 X
\\Y
 \\Z
 \\1

\end{pmatrix}$$
T一共有12维，因此最少通过6对匹配点即可实现矩阵T的线性求解，这种方法称为DLT。当匹配点大于6对时，也可以使用SVD等方法对超定方程求最小二乘解。
<br> 这样求得的最小二乘解是没有尺度的

### 7.7.2 P3P
它仅使用3对匹配点，此外，还需要使用一对验证点。
<br> 请注意，我们知道的是A,B,C在世界坐标系中的坐标，而不是在相机坐标系中的坐标。一旦3D点在相机坐标系下的坐标能够算出，我们就得到了3D-3D的对应点，把PnP问题转换为了ICP问题
$$ x^{2}+y^{2}-2xy\cos \left \langle a,b \right \rangle=v   $$

$$(1-u)y^{2}-ux^{2}-\cos\left \langle b,c \right \rangle y+2uxy\cos\left \langle a,b \right \rangle +1=0   $$
$$ (1-w)x^{2}-wy^{2}-\cos\left \langle a,c \right \rangle x+2wxy\cos\left \langle a,b \right \rangle +1=0   $$
3个余弦角cos<a,b>, cos<b,c>, cos<a,c>是已知的。同时，u=BC<sup>2</sup>/AB<sup>2</sup>，v=AB<sup>2</sup>/OC<sup>2</sup>， w=AC<sup>2</sup>/AB<sup>2</sup>可以通过A,B,C在世界坐标系下的坐标算出，变换到相机坐标系下之后，这个比值并不改变。该式中的x=OA/OC，y=OB/OC是未知的，随着相机移动会发生变化。

求该方程组的解析解是一个复杂的过程，需要用吴消元法。该方程最多可能得到4个解，但我们可以用验证点来计算最可能的解，得到A, B, C在相机坐标系下的3D坐标。然后，根据3D-3D的点对，计算相机的运动R, t。

在SLAM中，通常的做法是先使用P3P/EPnP等方法估计相机位姿，再构建最小二乘优化问题对估计值进行调整（即进行Bundle Adjustment）。

### 7.7.3 最小化重投影误差求解PnP
这一类把相机和三维点放在一起进行最小化的问题，统称为Bundle Adjustment。

$$ T^{*}=arg\min_{T}\frac{1}{2}\sum_{i=1}^{n}\left \|u_{i}-\frac{1}{s_{i} }KTP_{i}     \right \|_{2}^{2}      $$
该问题的误差项，是将3D点的投影位置与观测位置作差，所以称为重投影误差。
<br> 我们需要知道每个误差项关于优化变量的导数，也就是线性化：

除了优化位姿，我们还希望优化特征点的空间位置。

## 8.1 直接法的引出
特征点法缺点：
+ 关键点的提取与描述子的计算非常耗时
+ 忽略了除特征点外的所有信息
+ 特征点缺失——没有明显纹理信息的地方

最小化重投影误差
最小化光度误差

只要场景中存在明暗变化（可以是渐变，不形成局部的图像梯度），直接法就能工作。根据使用像素的数量，直接法分为稀疏、稠密和半稠密三种。特征点法只能重构稀疏特征点（稀疏地图）。

***
## PTAM related
[Parallel Tracking And Mapping (PTAM) 特征点法 fast角点+灰度块匹配 2d-2d单应变换](https://github.com/Ewenwan/MVision/tree/master/vSLAM/PTAM)

2、PTAM是第一个使用 非线性优化，而不是使用传统的 滤波器 作为后端的方案。
它引入了关键帧机制：我们不必精细地处理每一幅图像，而是把几个关键图像串起来，然后优化其轨迹和地图。

ORB-SLAM就是继承并改进PTAM的

具体而言:
1. 姿态跟踪线程 不修改地图，只是利用已知地图来快速跟踪；
2. 而在建立 地图线程 专注于地图的建立、维护和更新。  

但很现实的问题是如果地图建立或优化过慢，跟踪线程很容易会因为没有最新的地图或者没有优化过的地图而跟丢。
<br> <font color=red>？</font> 另外比较实际的工程问题是地图线程的最新地图数据应该lock 还是 copy data between threads 以及threading的实现质量。

PTAM主要分为这几部分：
1) **Track线程**
1. 金字塔分层，FAST特征提取
(对图片构造金字塔的目的有两个：1）加快匹配；2）提高地图点相对于相机远近变化时的鲁棒性)
(FAST是常用的特征点，优点是快，缺点是不鲁棒.通常先提取出大量匹配点，后使用SSD快匹配，剔除误匹配)
2. 地图初始化
3. 跟踪定位 （极线几何与极线搜索， RANSAC（随机采样一致）及N点算法（主要围绕5点算法））
4. 选取添加关键帧到缓存队列
5. 重定位(每帧高斯模糊小图SSD相似度匹配)
2) **Map线程**
6. 先五点法加RANSAC求出初值
7. 局部BundleAdjustment
8. 全局BundleAdjustment
9. 从缓存队列取出关键帧到地图
10. 极线搜索加点到地图

另一方面，按照一般的视觉SLAM框架，PTAM也可分为
1) 传感器数据获取（摄像头输入图像数据）
2) 前端视觉里程计（跟踪定位、重定位）
3) 后端优化（Bundle Adjustment）
4) 建图（极线搜索加点）
5) 没有回环检测

缺点：场景小，跟踪容易丢失。

![](/monocular/img/ptam1.png)

[PTAM跟踪过程中的旋转预测方法](https://zhuanlan.zhihu.com/p/20302059?refer=computercoil)
<br> PTAM在进行跟踪的每一帧都会首先调用一个CalcSBIRotation的方法，最开始读PTAM代码我总是很疑惑这个方法的作用。最后发现这个方法会计算一下当前帧相对于上一帧的Rotation。也就是旋转角度。计算完毕后再根据这个旋转角度进行调整，然后使用基于SSD的跟踪算法。因为预先计算了Rotation，当然SSD的结果也就会更加准确。当用户旋转摄像头的时候也就更加不容易丢失跟踪目标。

此方法采用的跟踪算法为 ESM 跟踪算法。

[PTAM学习](https://gjgjh.github.io/ptam.html#/i-%E8%B7%91ptam)

2.2准备跟踪
下一章将解析跟踪线程的流程。但实际工作中，构建线程是同时工作的。在跟踪之前已经完成了构建地图的初始化工作。此时我们至少有以下数据进行跟踪:
+ 每个点的世界坐标系位置(mm)。
+ 第一次观测到该点的帧的ID索引。称这个关键帧为该点的源帧。
+ 该点在帧图像中的位置(像素)，记为rootPos(u，v)。
+ rootPos的右边像素(u+1，v)和下一像素(u，v+1)在平面P中的投影。平面P在下一节定义。
+ 每一关键帧的视图矩阵。
+ 每一关键帧观测到的点的索引集合。
+ 每个关键帧的灰度图像金字塔，每个四层。

实际上，保存这些数据就想当于保存地图，下次启动时可以直接加载地图免去初始化工作，直接开始跟踪。我们可以保存除这些数据外更多的中间变量免去加载地图后的部分计算。

### 3.1 仿射变换
目标与图像采集设备之间的距离通常较远，其三维变化常可以用二维变化来近似，所以，在兼顾算法效果和计算效率的考虑之下，经常可以选择使用了六参数的仿射变换运动模型。

二维仿射变换有6个自由度，分别是两个平移,两个旋转旋转，一个错切,和一个缩放。

### 3.3计算扭曲矩阵
![](/monocular/img/niu.jpg)

一般我们是先配准，再重投影，再优化的一个过程，但PTAM的顺序是先重投影，再配准，再优化。前两步共同完成了数据关联。

***

## 相机标定/失真校正  
"Straight lines have to be straight"
$$ r=\sqrt{\frac{x^{2}+y^{2}  }{z^{2} } } $$
$$ r'=\frac{1}{\omega }\arctan (2r\tan \frac{\omega}{2} ) $$
系数 
$$\frac{r'}{r}$$
